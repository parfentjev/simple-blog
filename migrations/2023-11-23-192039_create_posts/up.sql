CREATE TABLE posts
(
    id      varchar(255) not null,
    title   varchar(255) not null,
    summary varchar(255) not null,
    text    varchar(255) not null,
    date    varchar(255) not null,
    visible boolean not null,
    primary key (id)
);

INSERT INTO posts (id,date,summary,"text",title,visible) VALUES
                                                            ('64f0db022737eb44cd0ed9a7','2023-08-31T17:18:18.985Z','Not so long ago, electric vehicles were considered gimmick. For people like myself with no special interest in them, it all began with the likes of Nissan Leaf and Mitsubishi i-MieV, with Tesla joining the party a few years later. I''d never actually thought who their ancestors could be  until I stumbled upon this [Mastodon post](https://strangeobject.space/@SallyStrange/110974167953077543) about an adorable little car called the Citicar or Comuta-Car.','Not so long ago, electric vehicles were considered gimmick. For people like myself with no special interest in them, it all began with the likes of Nissan Leaf and Mitsubishi i-MieV, with Tesla joining the party a few years later. I''d never actually thought who their ancestors could be until I stumbled upon this [Mastodon post](https://strangeobject.space/@SallyStrange/110974167953077543) about an adorable little car called the Citicar or Comuta-Car.

![Late 6HP CitiCar electric car at the America on Wheels Auto Museum](/media/64f0db022737eb44cd0ed9a7/1976_Citicar_6HP.jpg)

At the end of 1973, [the oil crisis](https://en.wikipedia.org/wiki/1973_oil_crisis) affected the lives of many people around the world. Not only did gas become more expensive, but it also was scarce. Rationing, empty stations, violence and strikes were part of the worrying reality back then. You can''t find a better time to release a non-petroleum car. It hit the market in 1974. In the [video promoting the car](https://www.youtube.com/watch?v=KSZLend0KBc), they emphasized high fuel prices, talked about the energy crisis and mentiond that it could help with the pollution. It''s been 49 years and we haven''t solved any of these issues, still selling modern electric vehicles as the solution!

![An all-electric Sebring CitiCar (left) and a modern Tesla Model X parked at loading cargo area in San Francisco, CA.](/media/64f0db022737eb44cd0ed9a7/EV_generation_1_and_2.jpg)

A company name Sebring-Vanguard designed three models. With a few practical improvements, they introduced more powerful motors and higher-voltage battery packs. A few years later, Commuter Vehicles bought the project and renamed it to Comuta-Car. There was also a slightly bigger and more powerful model - Comuta-Van. The United States Postal Service even ordered a few hundreds, but according to several sources, [technical issues and a dispute over warranty terms](http://www.postal-reporter.com/blog/photo-futuristic-looking-usps-mail-delivery-vehicle-from-1970s/) halted the project. They stopped making Comuta-Cars in 1982.

![1975 Sebring-Vanguard CitiCar at the Automobile Driving Museum](/media/64f0db022737eb44cd0ed9a7/1975_Sebring-Vanguard_CitiCar_-_Automobile_Driving_Museum_-_El_Segundo_CA_-_DSC01704.jpg)

By the way it looks, that wasn''t a very successful business. Besides the technical problems with the car itself and troubles they might''ve had with bringing investments and scaling up production, we also need to consider technologies that were available at that time. Rechargable lithium-ion batteries weren''t a thing yet, the vehichles came with lead-acid batteries. Those are much cheaper, but their capacity is significantly lower.

![A yellow Citicar, front angle](/media/64f0db022737eb44cd0ed9a7/Citicar_front-angle.jpg)

Insights about how it was like to own one of them can be found on [Jalopnik](https://jalopnik.com/before-tesla-there-was-comuta-1846846642). It''s a story of a man who owned a Comuta-Van in the 1990s. Key takeaways:

- It could run up to 40 miles (64 kilometers) on a single charge.
- The top speed was 45 mph (72 km/h).
- He had a solar array at the root, but it only added a few miles per day.
- A full charge took about 12 hours.
- The batteries needed to be topped up with distilled water every few weeks, which took a decent amount of time.
- He had to replace the batteries twice in four years, that cost under under $1,000 (today that''d be roughly $1,900).

I can imagine that 40 miles in the US is close to nothing. However, that top speed should be sufficient in the city. Something like that could be useful for commuting to the office and back or for grocery trips. According to the owner, the Postal Van version has a lot of room in the back, so it should''ve been quite practical.

![The postal (USPS) eiditon of the Comuta-Van](/media/64f0db022737eb44cd0ed9a7/electric-postal-vans-1981-1024x703.jpeg)

After all these years, the concept of a small electric transport is still relevant. Big brands produce vehicles like CitroÃ«n Ami and Renault Twizy, but there are other [quadricycle manufacturers](https://en.wikipedia.org/wiki/Quadricycle_(EU_vehicle_classification)). Through 1990s and 2000s, similar cars were built by [Kewet](http://www.kewet.de/historie/buddy/index.htm) and [Buddy](https://en.wikipedia.org/wiki/Buddy_(electric_car)).

![2021 Citroen Ami taken in Valbonne, France](/media/64f0db022737eb44cd0ed9a7/2021_Citroen_Ami.jpg)

Shame on my ignorance, as there were electric vehicles long before Nissan Leaf and Mitsubishi i-MieV! It''s true that there were only thousands of units, not even tens of thousands. Nevertheless, they''re still on the road and you can find many videos about them on [YouTube](https://www.youtube.com/watch?v=hXzcIoq2ing). When thinking of that era, legends like Chevrolet Camaro, Dodge Challenger or Plymouth Roadrunner come to mind. Turns out, there are many interesting things to discover in our recent past!

Useful links:

- [https://en.wikipedia.org/wiki/Citicar](https://en.wikipedia.org/wiki/Citicar)
- [https://jalopnik.com/before-tesla-there-was-comuta-1846846642](https://jalopnik.com/before-tesla-there-was-comuta-1846846642)
- [https://ranwhenparked.net/first-electric-car/](https://ranwhenparked.net/first-electric-car/)
- [https://web.archive.org/web/20220323000934/https://www.wheels.ca/news/electric-car-for-the-average-joe-not-far-away/](https://web.archive.org/web/20220323000934/https://www.wheels.ca/news/electric-car-for-the-average-joe-not-far-away/)
- [https://www.youtube.com/watch?v=hXzcIoq2ing](https://www.youtube.com/watch?v=hXzcIoq2ing)
- [https://www.youtube.com/watch?v=KSZLend0KBc](https://www.youtube.com/watch?v=KSZLend0KBc)
- [https://www.motorbiscuit.com/comutavan-electric-postal-van/](https://www.motorbiscuit.com/comutavan-electric-postal-van/)

All photos, with the exception of the one with Postal Vans, were taken from the [Wikimedia Commons](https://commons.wikimedia.org/) library. I found Postal Vans on [USAMotorJobs](https://news.usamotorjobs.com/).','Citicar: Small electric car from 1970s',1),
                                                            ('6504a9b57cea059700edcc66','2023-09-15T19:02:16.267Z','A few weeks ago, a potential employer asked me to complete a test assignment. The task was to implement a bunch of API and UI tests. This requirement is quite standard in the field, but I had not previously compiled any work ready to be shared alongside my CV.

Therefore, I made the decision not only to complete the assginment but also to document and explain it here in this blog post.','A few weeks ago, a potential employer asked me to complete a test assignment. The task was to implement a bunch of API and UI tests. This requirement is quite standard in the field, but I had not previously compiled any work ready to be shared alongside my CV.

Therefore, I made the decision not only to complete the assignment but also to document and explain it here in this blog post.

- Explaining things helps me to understand them better.
- This post will help me to refresh my memory in the future.
- When sharing my code, I can supply it with this post. It''s particularly useful as it answers questions like "Why did you choose to implement X in this way?"
- Other automation engineers can find it useful! There are a lot of articles aimed at software developers, but not as many for test engineers. By sharing my experience, I hope to help them.

I want to emphasize that I don''t claim to possess exhaustive knowledge, and my experience is limited. There might be better ways to approach certain tasks, and my code can certainly be improved. I always seek information from multiple sources and I encourage you to do the same.

Constructive feedback is always welcome! If you''d like to connect or provide feedback, you can find me on [LinkedIn](https://www.linkedin.com/in/aleksei-parfentjev-8b7103118/) or reach out via [email](mailto:contact@fakeplastictrees.ee).

Please note that code snippets in this post are simplified. The full project is available [here](https://codeberg.org/parfentjev/monese-test-assignment).

## Requirements

First of all, let''s look at the requirements that I got from the company:

- Implement API tests with [REST Assured](https://rest-assured.io/).
- Implement UI tests for Android with [Appium](http://appium.io/docs/en/2.1/).
- Implement 3 tests:
  - A positive test.
  - A negative test.
  - A test that always fails.
- Write code that is easy to maintain and expand.
- Generate a test report after the execution.
- Provide human-readable descriptions for automated tests.

## Project structure

One might argue, that separate projects and repositories should be used for API and UI tests. They work independently from each other and don''t share much code. However, they do share _some_ code. For instance, both API and UI manipulate external data in the form of strings. Utility classes that hold common data conversion, parsing and validation methods can be used in both projects. Additionally, frequently used regex patterns should be available for easy reuse too.

Another reason to combine projects comes from the fact that UI tests tend to be slow and unstable. By replacing some of repetitive UI scenarios with API calls, we can save a lot of time and get ourself a more stable suite.

Consider a system under test, where the user can create an account. To avoid issues with the account configuration, we run our tests using fresh accounts. It makes sense to create and verify these accounts primarily through API calls rather than relying on the UI. UI interactions should be reserved for tests that specifically validate the account creation process.

With that in mind, I decided that a single multi-module project was the best approach here.

```bash
.
âââ api-test
âââ shared
âââ ui-test
âââ pom.xml
```

In addition to the API and UI test modules, I created a shared module.

## Shared module

The shared module serves two purposes:

- It contains all code that isn''t exclusively dedicated to either API or UI tests: utility classes and functionality that both API and UI tests require.
- It can be safely used as a dependency for any other module.

The latter is important. Maven doesn''t allow for two modules to depend on each other. That''d be a [circular dependency](https://en.wikipedia.org/wiki/Circular_dependency):

> In software engineering, a circular dependency is a relation between two or more modules which either directly or indirectly depend on each other to function properly. <...> Circular dependencies between larger software modules are considered an anti-pattern because of their negative effects.

Consider the following scenario:

- Module **A** depends on Module **B**.
- Module **B** depends on Module **A**.

When Maven attempts to compile Module **A**, it identifies Module **B** as a dependency and tries to compile it first. However, since Module **B** relies on Module **A**, this creates an endless loop in the compilation process. By creating a shared module, we eliminate this problem.

As for the content of the shared module, it includes [two utility classes](https://codeberg.org/parfentjev/monese-test-assignment/src/branch/main/shared/src/main/java/org/monese/shared). Since both API and UI test modules interact with property files, I created a dedicated [Configuration](https://codeberg.org/parfentjev/monese-test-assignment/src/branch/main/shared/src/main/java/org/monese/shared/Configuration.java) class to handle properties initialization and data retrieval. This approach minimizes code duplication. For more complex projects with multiple property files (e.g. for different test environments), the Maven property plugin or environment variables can be used to specify the property file dynamically.

It''s also worth noting that the API framework (`./api-test/src/main/java/org/monese/apitest/`) could be stored in the shared module if I was planning to use it in the UI test module.

> By replacing some of repetitive UI scenarios with API calls, we can save a lot of time and get ourself a more stable suite.

But that''s not the case in this assignment. API and UI modules test different applications.

## API tests

The basic usage of REST Assured is straightforward:

```java
given()
    .baseUri("https://some-service.com") // the address of the API server
    .header("Authorization", "Bearer " + "your token") // the API token
    .log().everything() // logs request details to the console
    .get("/user/1"); // the acutal GET request to https://some-service.com/user/1
```

This code makes a request to retrieve a user with the ID of 1. The `get` method returns a `Response` object that offers various tools to validate the response. For example, you can verify that the request was successful (status code = 200) and that the `id` and `email` fields contain the expected data.

```java
Response response = given()
    .baseUri("https://some-service.com")
    .header("Authorization", "Bearer " + "your token")
    .log().everything()
    .get("/user/1");
nresponse.then()
    .statusCode(200)
    .body("id", equalTo(1)) // verify that the id=1
    .body("email", equalTo("expected@email.com")); // verify that the email=expected@email.com
```

However, this approach doesn''t scale well and could cause problems in a big automation project with hundreds of tests.

- Services may have dozens and even hundreds of endpoints, making it impossible to memorize them all.
- Each endpoint accepts and returns different data.
- Services change over time. Even in a small QA team, not everyone may be aware of these changes.
- If a field''s name changes, you''d need to manually update all references to it in the code.
- The removal of obsolete fields can be quite challenging even with static analysis tools.
- As an object-oriented language, Java benefits from classes that describe requests and responses, reducing the issues mentioned above.

To address these points, I introduced an API executor layer.

- It acts as a bridge between tests and the API server.
- It accepts Java objects as requests.
- It returns Java objects as responses.

Instead of using the previous approach where we had to manually specify the expected structure, you can do it only once:

```java
public class GetUsersByIdResponse {
    Long id;

    String email;

    String name;

    UserGender gender;

    UserStatus status;

    // getters and setters
}
```

And deserialize the JSON response to a Java object:

```java
GetUsersByIdResponse response = given()
    .baseUri("https://some-service.com")
    .header("Authorization", "Bearer " + "your token")
    .log().everything()
    .get("/user/1")
    .as(GetUsersByIdResponse.class); // converts JSON to GetUsersByIdResponse

    assertThat(response.getId()).isEqualTo(1);
    assertThat(response.getEmail()).isEqualTo("expected@email.com");
```

This approach simplifies test development. Even if the automation engineer is unfamiliar with the potential response, they can always refer to the `GetUsersByIdResponse` class or use code hints.

![IntelliJ IDEA code suggestions](/media/6504a9b57cea059700edcc66/response-code-suggestions.jpg)

![IntelliJ IDEA method usage](/media/6504a9b57cea059700edcc66/code-usage.jpg)

While retrieving data is straightforward, creating or modifying it on the server can be difficult. You may need to send complex objects with multiple fields and nested objects. By navigating through the codebase you can quickly find how other people deal with similar problems.

In the code above, you still need to know all response classes to feed them to the `as(ClassName.class)` method. This is where a dedicated API execution layer becomes especially useful.

```java
public class ApiExecutor {
    public static GetUsersByIdResponse getUsersById(Integer userId) {
        return given()
                .baseUri("https://some-service.com")
                .header("Authorization", "Bearer " + "your token")
                .log().everything()
                .get("/user/" + userId)
                .as(GetUsersByIdResponse.class);
    }
}
```

With this, you can call the `getUsersById` method in any test and receive a deserialized response object. Great success!

```java
@Testnpublic void getUsersById() {
    GetUsersByIdResponse response = ApiExecutor.getUsersById(1);

    assertThat(response.getId()).isEqualTo(1);
    assertThat(response.getEmail()).isEqualTo("expected@email.com");
}
```

Unfortunately, this solution works only with positive test cases. It doesn''t allow verifying the status code or reading the error message in negative tests. The test above would simply fail during the deserialization, because the error response contains different fields.

To address this issue and provide flexibility for handling various response scenarios, I created the `ExtendedResponse` class. [Generics jn Java](https://www.baeldung.com/java-generics) make it possible:

```java
// T is a placeholder for the actual response classnpublic class ExtendedResponse<T> {
    private final Response response;
    private final Class<T> responseClass;

    public ExtendedResponse(Response response, Class<T> responseClass) {
        this.response = response;
        this.responseClass = responseClass;

        response.prettyPeek(); // prints out the response body to the console
    }

    // verify the status code
    public ExtendedResponse<T> statusCode(int statusCode) {
        response.then().statusCode(statusCode);

        return this;
    }

    // get the deserialized response and work with it
    public ExtendedResponse<T> responseConsumer(Consumer<T> consumer) {
        consumer.accept(response.as(responseClass));

        return this;
    }

    // get the validatable response (REST Assured) and work with it
    public ExtendedResponse<T> validatableConsumer(Consumer<ValidatableResponse> consumer) {
        consumer.accept(response.then());

        return this;
    }
}
```

This extended response class holds both the REST Assured `Response` object and the deserialized class. I decided not to expose the `Response` class, because it would be a dead end - it can''t return the `ExtendedResponse` back.

With these changes, a positive test looks like this:

```java
ApiExecutor.getUsersById(1)
    .statusCode(200)
    .responseConsumer(response -> {
        assertThat(response.getId()).isEqualTo(1);
        assertThat(response.getEmail()).isEqualTo("expected@email.com");
    });
```

A negative test:

```java
ApiExecutor.getUsersById(-1)
    .statusCode(200)
    .validatableConsumer(response -> {
        response.body("message", equalTo("user doesn''t exist"));
    });
```

Moreover, we can handle standard errors responses too:

```json
{
    "message": "user doesn''t exist"
}
```

Just add a method to verify the error message:

```java
public ExtendedResponse<T> errorMessage(String message) {
    response.then()
            .body("message", equalTo(message));

    return this;
}
```

And use it in your test:

```java
ApiExecutor.getUsersById(-1).errorMessage("user doesn''t exist");
```

Finally, here''s the updated API executor for your reference:

```java
public class ApiExecutor {
    private final String baseUrl;
    private final String token;

    public ApiExecutor(String baseUrl, String token) {
        this.baseUrl = baseUrl;
        this.token = token;
    }

    private RequestSpecification restAssured() {
        return given()
                .baseUri(baseUrl)
                .header("Authorization", "Bearer " + token)
                .log().everything();
    }

    public ExtendedResponse<GetUsersByIdResponse> getUsersById(Long id) {
        return new ExtendedResponse<>(restAssured().get("/user/" + userId), GetUsersByIdResponse.class);
    }
}
```

Now there''s a layer that holds all available API requests and responses. You can find more [examples in the final project](https://codeberg.org/parfentjev/monese-test-assignment/src/branch/main/api-test/src/main/java/org/monese/apitest/util/ApiExecutor.java), where you''ll find how to send data to the server. My API tests are available [here](https://codeberg.org/parfentjev/monese-test-assignment/src/branch/main/api-test/src/test/java/org/monese/apitest/UsersApiTest.java).

## UI tests

The requirements tasked me to create an Android application with Appium. I''ve never worked with it! Appium is based Selenium and reuses same classes and tools, which is good news for many test engineers who are familiar with Selenium. However, I''ve never worked with it either! Therefore, I''m not going to focus on these two libraries. Both suggest using the [page object model](https://www.selenium.dev/documentation/test_practices/encouraged/page_object_models/) that I''m familiar with.

From what I''ve heard, the bare Selenium lacks many things, making tests harder to develop. Some teams prefer a more advanced Selenide because of that, some simply extend Selenium - and so did I. I created an `Element` class to serve as a wrapper for the `WebElement` class.

```java
public class Element {
    private final WebElement webElement;

    public Element(WebElement webElement) {
        this.webElement = webElement;
    }

    // extending the WebElement''s functionality
    public Element requireText(String value) {
        await(() -> webElement.getText().equals(value));

        return this;
    }

    // delegate
    public void click() {
        webElement.click();
    }

    // delegate
    public void submit() {
        webElement.submit();
    }

    // delegate
    public void sendKeys(CharSequence... keysToSend) {
        webElement.sendKeys(keysToSend);
    }

    // and so on...
}
```

This classes delegates default `WebElement` behavior to maintain its behavior. However, I added a `requireText` method to handle awaits in one place, since the expected text may not be immediately visible. This also provides a convenient Java interface for working with elements, making the test code more readable.

```java
public Element requireText(String value) {
    await(() -> webElement.getText().equals(value));

    return this;
}
```

Now I can use it in tests with any element on the page without thiking about awaits and assertions:

```java
pageObject.getSomeField().requireText("some text")
```

Moreover, you can add more methods and chain them:

```java
pageObject.getSomeField()
    .requireText("some text")
    .requireDisabled()
    .awaitEnabled()
    .click()
```

This approach makes test development easier and faster. Also, it reduces the amount of bugs in tests and the framework itself! All dirty work is being done behind the scenes.

Another essential addition is the `ElementList` class, designed to work with lists of elements:

```java
public class ElementList {
    private final List<Element> elements;

    public ElementList(List<Element> elements) {
        this.elements = elements;
    }

    public Element singleElementBy(Predicate<Element> predicate) {
        List<Element> items = elements.stream().filter(predicate).collect(Collectors.toList());

        assertThat(items)
                .overridingErrorMessage("Expected 1 element, but found %d.", items.size())
                .hasSize(1);

        return items.get(0);
    }
}
```

This class simplifies working with lists of elements, commonly found in UI testing: rows in a `<table>`, items of a list (`<ol>`/`<ul>`) or of a dropdown menu. Each row or item is already represented by a Java object, allowing you to use familiar Java tools to interact with them.

For instance, you can easily select a single element from a list based on specific criteria:

```java
mainScreen.clickExpandMenuButton()
    .clickSettingsButton()
    .getServiceProviders()
    .singleElementBy(e -> e.getText().equals("DeepL")) // finds a single translation by name
    .click();
```

With this method, you don''t need to handle filtering and asserting that only one element matches the criteria. I''ve used a similar framework on projects with over 1500 end-to-end UI tests. It greatly simplifies test development and maintenance even on that scale.

My UI test are available [here](https://codeberg.org/parfentjev/monese-test-assignment/src/branch/main/ui-test/src/test/java/org/monese/uitest/TranslateYouUiTest.java).

## Summary

I hope that with the codebase and this post, it''s now more or less clear how this project works and why I made some decisions. I firmly believe that common Java development practices allow us to write tests more efficiently, mitigate most potential issues and scale this framework to a much larger scope.

If you have any questions, ideas or suggestions, please feel free to reach out. Your input is always welcome.','Basic API and UI test automation framework',1),
                                                            ('650b15e825711de187e145e5','2023-09-20T15:56:47.591Z','I''ve watched several documentaries over the past couple of months and wanted to jot down my impressions. Here''s the list:

- Unknown: Cave of Bones
- WWII in Color: Road to Victory
- A Compassionate Spy
- MH370: The Plane That Disappeared','I''ve watched several documentaries over the past couple of months and wanted to jot down my impressions. Here''s the list:- Unknown: Cave of Bonesn- WWII in Color: Road to Victoryn- A Compassionate Spyn- MH370: The Plane That Disappeared

## Unknown: Cave of Bones

![Unknown: Cave of Bones poster](/media/650b15e825711de187e145e5/Unknown-Cave-of-Bones-poster.jpg)

_Source: [https://www.imdb.com/title/tt27837467/](https://www.imdb.com/title/tt27837467/)_

From [Wikipedia](https://en.wikipedia.org/wiki/Homo_naledi):

> Homo naledi is an extinct hominin species discovered in 2013 in the Rising Star Cave system, Gauteng province, South Africa, dating to the Middle Pleistocene 335,000â236,000 years ago. The initial discovery comprises 1,550 specimens of bone, representing 737 different skeletal elements, and at least 15 different individuals.

The documentary shows one of the latest expiditons to South Africa with scientists who discovered the remains back in 2013.

![Cross-section of the Rising Star Cave system Dinaledi Chamber](/media/650b15e825711de187e145e5/Cross-section_of_the_Rising_Star_Cave_system_Dinaledi_Chamber.jpg)

_Source: [https://en.wikipedia.org/wiki/File:Cross-section_of_the_Rising_Star_Cave_system_Dinaledi_Chamber.svg](https://en.wikipedia.org/wiki/File:Cross-section_of_the_Rising_Star_Cave_system_Dinaledi_Chamber.svg)_

Even with flashlights and rock climbing gear that is available today, navigating the case system is not easy. For unknown reasons, Homo naledi chose to use it to its fullest extent: the remains were found in the furthest part of the cave - the Dinaledi Chamber. Reaching this location is challenging, the movie conveys that well. It also includes interviews with the team and scientists, who conducted the project. Additional animations help fill in gaps, portraying how this species may''ve looked like and interacted with each other.

Critics point out that "Unknown: Cave of Bones" isn''t scientific enough and that some of the team''s theories are unproven. I had a similar impression while watching it. However, it''s clear that scientists are not the target audience. To me, it was a fascinating glimpse into how palaeoanthropologists work. Can they be biased towards their discoveries and hyphiteses? Well, certainly! Nevertheless, the film can be interesting for a casual audience.

## WWII in Color: Road to Victory

![WWII in Color: Road to Victory poster](/media/650b15e825711de187e145e5/WWII-in-Color-Road-to-Victory-poster.jpg)

_Source: [https://www.imdb.com/title/tt16477402/](https://www.imdb.com/title/tt16477402/)_

From [Netflix](https://www.netflix.com/title/81488464):

> Gripping historical footage and expert commentary give detailed insights into the leading figures and decisive turning points of World War II.

Growing up in a Russian informational bubble, I became familiar with the key battles between the Nazis and the Soviet Union. To this day, journalists, bloggers and regular people are bringing up the topic of war in various discussions. This series primarily focuses on the Western front, Northen Africa and the Pacific.

One might argue that this isn''t fair. The Soviet Union lost more than 20 million people in the bloodbath, there''s much more to be said about struggles on the Eastern front. But I employ a different approach to information. I already know about that and if I wanted to learn more, I could find another source. "WWII in Color: Road to Victor" allowed me to see what was happening in other parts of the world.

Various historians and authors participated in the filming, the narrative is complemented by historical video footage. This is especially visible in the final part, which focuses on the US and Japan. It appears that many American journalists were present with their cameras, capturing key events. This intensifies the emotional response and keeps you engaged.

Today, many of us live in relatively good conditions away from Ukraine and other military conflicts. It can be hard to fully comprehend the horrors of a war. We should remind ourselves about them, as playing with fire can lead to terrible consequences. In my opinion, the movie is good at that without being overly dramatic.

Lastly, historical events are always open to interpretation. For me, the most debatable passage in the documentary is that the atomic bombings were necessary and even good, because that helped to save lives. This statement doesn''t have a universal support.

Other than that, it''s an interesting overview of different events from a Western point of view.

## A Compassionate Spy

![A Compassionate Spy poster](/media/650b15e825711de187e145e5/A-Compassionate-Spy-poster.jpg)

_Source: [https://www.imdb.com/title/tt21376858/](https://www.imdb.com/title/tt21376858/)_

From [Wikipedia](https://en.wikipedia.org/wiki/A_Compassionate_Spy):

> A Compassionate Spy is a 2022 American documentary film written and directed by Steve James. Through a long interview with the subject and his wife, archive footage and some dramatic reenactments, the film tells the story of Manhattan Project physicist and Soviet Union spy Theodore Hall.

I haven''t seen the Oppenheimer movie yet, but I believe it could be a good addition to the topic. Another relevant piece of media is [The Bomb podcast](https://www.bbc.co.uk/programmes/p08llv8n/episodes/downloads) from the BBC. It''s about Klaus Fuchs, who was also a Soviet spy involved in [the atomic program](https://en.wikipedia.org/wiki/Manhattan_Project). I highly recommend listening both seasons.

While the podcast is more of a detective story that doesn''t explore Klaus''s motivation much, this documentary is built on interviews with the Theodore''s wife and children. It also contains fragments from his interview with the BBC. Naturally, the narrative is biased in favor the spy. Probably this is why the movie has 6.6 on IMDb. Unfortunately, there are no text reviews available to confirm my assumption.

I don''t see this bias as a bad thing. If anything, this is exactly what I wanted to know: his perspective. In the film, he''s indeed portrayed as a compassionate man who saw potential problems in the post-WWII world. He didn''t want the US to be the only country with the bomb. This idea is not new, people like the aforementioned Klaus Fuchs and others shared similar concerns. I won''t be the judge. If you want to understand this point of view better, go ahead and watch it.

## MH370: The Plane That Disappeared

![MH370: The Plane That Disappeared poster](/media/650b15e825711de187e145e5/MH370-The-Plane-That-Disappeared-poster.jpg)

_Source: [https://www.imdb.com/title/tt26739535/](https://www.imdb.com/title/tt26739535/)_

From [Wikipedia](https://en.wikipedia.org/wiki/MH370:_The_Plane_That_Disappeared):

> MH370: The Plane That Disappeared is a British docuseries released on Netflix and directed by Louise Malkinson about the 2014 disappearance of Malaysia Airlines Flight 370.

MH370 is a flight number of a Malaysian commercial airplane that vanished in March 2014 with 239 people on board. What exactly happened to it and why is still unknown.

The first episode focuses on the mainstream version of events. It present data from a British satellite, debris found ashore and a similar flight path discovered on the captain''s computer - he was an avid flight simulator fan. These factors point to the conclusion that the disappearance a deliberate act. However, the [official final report](https://web.archive.org/web/20201111205400/http://mh370.mot.gov.my/MH370SafetyInvestigationReport.pdf) didn''t provide a definitive answer. From page 443:

> In conclusion, the Team is unable to determine the real cause for the disappearanceof MH370.

That fueled speculations and alternative theories. Next two episodes of the documentary are dedicated to two of them:

1. The Russia hijacked the plane to divert attention from the war in Ukraine.
2. The US shot down the plane that was flying to Beijing, because it allegedly carried some sensitive technologies.

Of course, there are unanswered questions in the first theory and other hypotheses should be evaluated. But I don''t believe that alternative versions were critically addressed. Such allegations require ironclad evidence. This leaves a bad taste in your mouth, as many people have pointed out in reviews.

The series features relatives of those who were onboard. If you''re interested in the psychologycal aspect of this tradegy, you may want to watch it. Some people are grieving and rightfully demand answers, while some are trying to investigate.

Ultimately, this is what keeps me thinking. How do we cope with the loss of our loved ones? How can such grief change us? And finally, how would I react if I were in their shoes? We all experience the loss of close friends and relatives, but that rarely happens in such strange and confusing circumstances. It must be very challenging for the next of kin.

I recall reading [this article](https://archive.ph/DyZGM) from The Atlantic a couple of years ago. After briefly revisiting it today, I''d say it provides a more balanced overview of available facts. If you''re really interested in the topic, please spend time gathering more information from multiple sources before coming to conclusions.','Documentaries: September',1),
                                                            ('6522b7f62901b65123ad6d4e','2023-10-08T14:10:44.905Z','This year, I decided to ditch Postman. It had started pushing cloud integration up to an extent, where working without creating an account became nearly impossible. Many features were disabled in the "lightweight" mode. From a privacy perspective, I could have created an email alias, but I wasn''t happy with the overall direction of their development. Why invest time in a tool that is likely to become less customer-friendly and accessible in the future?','This year, I decided to ditch Postman. It had started pushing cloud integration up to an extent, where working without creating an account became nearly impossible. Many features were disabled in the "lightweight" mode.

![Disabled features in the Postman Lightweight API Client](/media/6522b7f62901b65123ad6d4e/2023-10-08_16-37.png)

From a privacy perspective, I could have created an email alias, but I wasn''t happy with the overall direction of their development. Why invest time in a tool that is likely to become less customer-friendly and accessible in the future? Recent changes made it clear that the company behind Postman is fully focused on monetization. That''s a worrying sign for end users. History has shown that such products tend to decline in quality.

![Sign up to save requests in the Postman Lightweight API Client](/media/6522b7f62901b65123ad6d4e/2023-10-08_16-39.png)

While exploring alternatives, I was surprised by how few options there are. While in absolute numbers it may look fine, I can''t say that they all offer a comparable set of features and user experience. One tool that caught my eye was [Insomnia](https://insomnia.rest/). It''s similar to Postman and allows you to import existing collections, making the transition very easy.

![Import collections from different sources to Insomnia](/media/6522b7f62901b65123ad6d4e/2023-10-08_16-43.png)

In my subjective experience, only one important feature is missing: global headers. In Postman, you can set an API token in the collection or sub-directory settings to use it for all nested requests. Insomnia doesn''t support that out of the box. However, there''s a plugin named `insomnia-plugin-global-headers` that makes it possible.

![Install the insomnia-plugin-global-headers plugin in Insomnia](/media/6522b7f62901b65123ad6d4e/2023-10-08_15-40.png)

After installing the plugin, you need to add a special object in the environment properties - `GLOBAL_HEADERS`. In this object you can list any headers, such as the authorization method.

![Configure global headers in Insomnia](/media/6522b7f62901b65123ad6d4e/2023-10-08_15-41.png)

Moreover, you don''t need to do this for every environment. I specified global headers for the `Base Environment`, which is a top-level configuration. Then, I created a sub-environment for my local development environment, where I specified the exact token value. You can override this token for any environment. I think it''s really cool.

![Override global configuration in Insomnia](/media/6522b7f62901b65123ad6d4e/2023-10-08_15-43.png)

Unfortunately, it soon became evident that Insomnia was following in Postman''s footsteps. After the latest update a couple of days ago, the program suggested to create an account or use a local collection. I''d chosen the latter option, but all my previously existing requests were lost! Even though I didn''t have much data on my local machine, I found that experience unpleasant and worrisome.

Fortunately, this didn''t mean that I had to look for another API test tool. Insomnia is open-source and licensed [under the MIT license](https://github.com/Kong/insomnia/blob/develop/LICENSE) - one of the most permissive licenses. Naturally, I wasn''t the only person concerned about recent changes, so there''s a fork available: [Insomnium](https://github.com/ArchGPT/insomnium).

From their GitHub:

> Insomnium is a 100% local and privacy-focused open-source API client for testing GraphQL, REST, WebSockets, Server-sent events and gRPC in development/production. <...> Works 100% offline. <...> No cloud services, no tracking/communication to external servers behind the scene. <...> Insomnium is a fork of Kong/insomnia at 2023.5.8, the last commit before compulsory account login was introduced. In a sense, Insomnium is a community response to the latest product update that forces account creation without warning.

It''s not clear yet whether this fork will keep up with future Insomnia releases. Even if it doesn''t, the current version already provides a fully functional product I can use at work every day. If you''re also interested in your privacy and maintaining control of sensitive data, take a look at this fork or some other open-source solutions:

- [Hoppscotch](https://hoppscotch.io/)
- [Thunder Client](https://www.thunderclient.io/)
- [Postcode](https://github.com/rohinivsenthil/postcode)
- [Nightingale](https://nightingale.rest/)

I''d consider them if it weren''t for Insomnium. They are free and open-source. At the end of [this article](https://testfully.io/blog/top-5-postman-alternatives/), you can find a comparison table that includes these and other API test tools.','Alternative to Postman: Insomnia',1),
                                                            ('6536b9bd892cba1c4623bcbf','2023-10-23T18:21:40.528Z','[Testcontainers](https://testcontainers.com/) is a great tool for managing external services required for the proper functioning of an entire application or its components during testing. It automatically deploys these services before a test begins and then stops them once testing is over. This simplifies the process of running tests across multiple environments.

While working on integration tests for the service behind this blog, I stumbled upon an issue. It lies on the border between Testcontainers and Spring. When executing a single test or an entire class, everything worked as expected. But when executing multiple test classes (e.g. with `./gradlew test`), the database became inaccessible.

In this post I''m exploring one of the possible solutions to this issue.','[Testcontainers](https://testcontainers.com/) is a great tool for managing external services required for the proper functioning of an entire application or its components during testing. It automatically deploys these services before a test begins and then stops them once testing is over. This simplifies the process of running tests across multiple environments.

While working on integration tests for the service behind this blog, I stumbled upon an issue. It lies on the border between Testcontainers and Spring. When executing a single test or an entire class, everything worked as expected. But when executing multiple test classes (e.g. with `./gradlew test`), the database became inaccessible:

- TestClass1: worked as expected.
- TestClass2: the application couldn''t connect to the database.

To configure the container, I referred to [this post](https://spring.io/blog/2023/06/23/improved-testcontainers-support-in-spring-boot-3-1). It mentions the traditional way of setting up containers:

```java
@SpringBootTest
@Testcontainers
class MyIntegrationTests {
    @Container
    static Neo4jContainer<?> neo4j = new Neo4jContainer<>("neo4j:5");

    @Test
    void myTest() {
        // ...
    }

    @DynamicPropertySource
    static void neo4jProperties(DynamicPropertyRegistry registry) {
        registry.add("spring.neo4j.uri", neo4j::getBoltUrl);
    }
}

```

It also suggests a new approach:

```java
@SpringBootTest
@Testcontainers
class MyIntegrationTests {
    @Container
    @ServiceConnection
    static Neo4jContainer<?> neo4j = new Neo4jContainer<>("neo4j:5");

    @Test
    void myTest() {
        // ...
    }
}
```

Because it has several advantages:

> First, you have to type less code. Second, there''s no more "stringly" typed coupling between your integration tests and the Spring Boot auto-configurations through the properties. And third, you don''t have to look up (or remember) the property names.

This approach is more concise compared to the traditional method, so I decided to follow it:

```java
@Container
@ServiceConnectionnstatic MongoDBContainer mongoDBContainer = new MongoDBContainer("mongo:latest")
      .withCopyFileToContainer(MountableFile.forClasspathResource("/dump"), "/dump");

    protected AbstractIntegrationTest() {
        try {
            mongoDBContainer.execInContainer("mongorestore", "/dump");
        } catch (IOException | InterruptedException e) {
            throw new RuntimeException(e);
        }
    }
```

As suggested by the constructor''s name, I put this code into an abstract class that all integration tests extend. I also added a few lines to prepare the database for testing:

```java
// copies a MongoDB dump from src/test/resources/dump to the container
.withCopyFileToContainer(MountableFile.forClasspathResource("/dump"), "/dump")

// runs a MongoDB utility to import data from the dump to the container
mongoDBContainer.execInContainer("mongorestore", "/dump");
```

This setup worked perfectly when used with a single test class. However, the issue I described earlier appeared when I tried to execute all test classes. Logs and `docker ps` confirmed that a new container was created for each test class:

> 2023-10-23T20:32:27.374+03:00 INFO 21795 --- [ Test worker] tc.mongo:latest : Creating container for image: mongo:latest

> 2023-10-23T20:32:27.413+03:00 INFO 21795 --- [ Test worker] tc.mongo:latest : Container mongo:latest is starting: 6e5a91929393383ccb88c6c873ab251e03f7b55cb80cbee19e0116a589357bc4

> 2023-10-23T20:32:27.841+03:00 INFO 21795 --- [ Test worker] tc.mongo:latest : Container mongo:latest started in PT0.467165456S

```java
// yet...

com.mongodb.MongoSocketOpenException: Exception opening socket
 at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:73) ~[mongodb-driver-core-4.9.1.jar:na]
  at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:204) ~[mongodb-driver-core-4.9.1.jar:na]
   at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.lookupServerDescription(DefaultServerMonitor.java:199) ~[mongodb-driver-core-4.9.1.jar:na]
       at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:159) ~[mongodb-driver-core-4.9.1.jar:na]
        at java.base/java.lang.Thread run(Thread.java:833) ~[na:na]nCaused by: java.net.ConnectException: Connection refused
        at java.base/sun.nio.ch.Net.pollConnect(Native Method) ~[na:na]
         at java.base/sun.nio.ch.Net.pollConnectNow(Net.java:672) ~[na:na]
          at java.base/sun.nio.ch.NioSocketImpl.timedFinishConnect(NioSocketImpl.java:542) ~[na:na]
           at java.base/sun.nio.ch.NioSocketImpl.connect(NioSocketImpl.java:597) ~[na:na]
            at java.base/java.net.SocksSocketImpl.connect(SocksSocketImpl.java:327) ~[na:na]
             at java.base/java.net.Socket.connect(Socket.java:633) ~[na:na]
              at com.mongodb.internal.connection.SocketStreamHelper.initialize(SocketStreamHelper.java:107) ~[mongodb-driver-core-4.9.1.jar:na]
               at com.mongodb.internal connection.SocketStream.initializeSocket(SocketStream.java:82) ~[mongodb-driver-core-4.9.1.jar:na]
                at com.mongodb.internal connection.SocketStream.open(SocketStream.java:68) ~[mongodb-driver-core-4.9.1.jar:na]
                 ... 4 common frames omittednn``
```

Apparently, and this guess is based on empirical evidence rather than digging under the hood, `@ServiceConnection`didn''t trigger the update of the Spring application''s properties. In other words, properties like`spring.data.mongodb.uri`were set for`TestClass1`, but not for `TestClass2`, even though the container was recreated. At least, this was the impression that I got from the symptoms.

I decided to try the traditional container initialization:

```java
@Containernstatic MongoDBContainer mongoDBContainer = new MongoDBContainer("mongo:latest")
      .withCopyFileToContainer(MountableFile.forClasspathResource("/dump"), "/dump");

    protected AbstractIntegrationTest() {
        try {
            mongoDBContainer.execInContainer("mongorestore", "/dump");
        } catch (IOException | InterruptedException e) {
            throw a RuntimeException(e);
        }
}

// using the @DynamicPropertySource instead of @ServiceConnection
@DynamicPropertySourcenstatic
void initialize(DynamicPropertyRegistry registry) {
   registry.add("spring.data.mongodb.uri", mongoDBContainer getReplicaSetUrl);
}
```

In this version, I used the `@DynamicPropertySource` annotation to mark a method that modifies properties. Unfortunately, this approach didn''t resolve the issue either. It seems that neither `@ServiceConnection` nor `@DynamicPropertySource` were updating properties. So I decided to initialize the container manually:

```java
static final MongoDBContainer mongoDBContainer;

static {
    try {
        mongoDBContainer = new MongoDBContainer("mongo:latest");
        mongoDBContainer.start();
        mongoDBContainer.copyFileToContainer(MountableFile.forClasspathResource("/dump"), "/dump");
        mongoDBContainer.execInContainer("mongorestore", "/dump");
    } catch (IOException | InterruptedException e) {
        throw a RuntimeException(e);
    }
}

@DynamicPropertySourcenstatic void initialize(DynamicPropertyRegistry registry) {
   registry.add("spring.data.mongodb.uri", mongoDBContainer getReplicaSetUrl);
}
```

This approach resolved the issue! By moving the initialization to the static block, it now occurs only once and all tests use the same MongoDB container. There''s no need to update properties as they don''t change between tests. I''d also say that this is the desired behavior: you don''t have to recreate the database instance for each test class. It saves time if the dump is too big or if there are many services required for testing.

The current implementation satisfied my needs, and I didn''t explore additional options. As it usually is in programming, there could be other ways to achieve the same result. But the goal of this post was to describe the issue and one of the possible solutions. When I was searching online, I couldn''t find that detail anywhere! I hope it was helpful to someone ð
','Testcontainers and Spring: Datasource becomes inaccessible between test classes',1),
                                                            ('65395a55892cba1c4623bcc0','2023-10-25T18:11:16.070Z','I''ve watched several documentaries over the past couple of months and wanted to jot down my impressions. Here''s the list:

- Turning Point: 9/11 and the War on Terror
- Challenger: The Final Flight
- Hitler''s Circle of Evil','I''ve watched several documentaries over the past couple of months and wanted to jot down my impressions. Here''s the list:

- Turning Point: 9/11 and the War on Terror
- Challenger: The Final Flight
- Hitler''s Circle of Evil

## Turning Point: 9/11 and the War on Terror

![Turning Point: 9/11 and the War on Terror poster](/media/65395a55892cba1c4623bcc0/turning-point-9-11-and-the-war-on-terror-poster.jpg)

Source: [IMDb](https://www.imdb.com/title/tt15260794/)

This film covers the period from the [Soviet invasion](https://en.wikipedia.org/wiki/Soviet%E2%80%93Afghan_War) of Afghanistan in 1979 to the [withdrawal of US troops](<https://en.wikipedia.org/wiki/Withdrawal_of_United_States_troops_from_Iraq_(2020%E2%80%932021)>) in 2021. It includes interviews with the survivors of the attack, journalists, politicians, agents of FBI and CIA, NSA employees, US soldiers, Afghan citizens, and even a member of the Taliban. The broad set of speakers offers a thorough and critical review of causes and consequences of the 9/11 attack.

The movie raises some difficult questions. In a sense, the US aided people who attacked it in 2001 in repelling the Soviet invasion. Was this the right decision? Another interesting question is whether the punishment did fit the crime. By no means do I mean that this terrible attack should''ve been ignored. However, it took the US military a whole ten years to leave after they had killed [Osama bin Laden](https://en.wikipedia.org/wiki/Osama_bin_Laden) in 2011. Now, the Taliban has returned to power, and it appears that Iraq wasn''t related to al-Qaeda. Answers to these questions will shape our actions under similar conditions in the future.

The issue of privacy and surveillance by various entities is a big concern today. The documentary touches this subject too, explaining how programs like [PRISM](https://en.wikipedia.org/wiki/PRISM) became possible following the attack.

Turning Point: 9/11 and the War on Terror is an important film to watch.

## Challenger: The Final Flight

![Challenger: The Final Flight poster](/media/65395a55892cba1c4623bcc0/challenger-the-final-flight-poster.jpg)

Source: [IMDb](https://www.imdb.com/title/tt12930534/)

This movie is about the Challenger space shuttle that disintegrated after liftoff in 1986. It elucidates the significance of this particular flight, introduces the crew, explores the root cause of the disaster and the ensuing investigation. The film features experts, relatives, engineers from NASA, and the company that manufactured the failed rocket booster, providing a comprehensive review of the tragedy.

For me, one of the most interesting parts was about how space shuttles were perceived during that era. [This fragment](https://www.youtube.com/watch?v=l10jsdYfqlU) from Jerry Seinfeld''s 1985 performance highlights that it had become a routine just 4 years after the first launch. It''s hard to impress people after putting a man on the Moon. However, this mission stood out as a high school teacher [Christa McAuliffe](https://en.wikipedia.org/wiki/Christa_McAuliffe) was part of the crew. There''s a dedicated chapter in the documentary about the [Teacher in Space Project](https://en.wikipedia.org/wiki/Teacher_in_Space_Project) and the selection process she had gone through.

Challenger: The Final Flight is a well-told story about the final flight of the shuttle. If the topic interests you, I recommend watching it.

## Hitler''s Circle of Evil

![Hitler''s Circle of Evil poster](/media/65395a55892cba1c4623bcc0/hitlers-circle-of-evil-poster.jpg)

Source: [IMDb](https://www.imdb.com/title/tt6600720/)

At first glance, when you see the title and the poster, you might expect tabloid material. I certainly did, given how the figure of Hitler often attracts sensationalism on the internet. Imagine my surprise when I discovered it has an IMDb rating of 8!

The documentary opens by telling how Hitler had joined the Nazi Party and became their leader. But he''s not the main character. This movie is about his closest henchmen, namely:

- [Heinrich Himmler](https://en.wikipedia.org/wiki/Heinrich_Himmler)
- [Joseph Goebbels](https://en.wikipedia.org/wiki/Joseph_Goebbels)
- [Hermann GÃ¶ring](https://en.wikipedia.org/wiki/Hermann_G%C3%B6ring)
- [Rudolf Hess](https://en.wikipedia.org/wiki/Rudolf_Hess)
- [Albert Speer](https://en.wikipedia.org/wiki/Albert_Speer)
- [Martin Bormann](https://en.wikipedia.org/wiki/Martin_Bormann)

And others. I was surprised that Joachim von Ribbentrop doesn''t appear to be part of the inner circle, at least as the film portrays it. After all, he was the minister of foreign affairs from 1938, just before and during WWII.

Hitler''s Circle of Evil is a conventional historical documentary. It blends interviews with historians, footages from that period of time and reenactments. After so many years, these people may look like mythical figures, united behind their FÃ¼hrer and working tirelessly towards the common goal. Turns out, they never trusted each other. Each man wanted to fulfill his own ambitions. Sometimes they formed alliances to undermine other members of the inner circle and increase their own power.

In essence, it''s politics driven by insane ideology. The movie is good at describing characters, their motivations, dynamics between them and how these were evolving from 1920 to 1945.','Documentaries: October',1),
                                                            ('653fbe98b17e464fde308117','2023-10-30T14:35:58.432Z','While learning a new programming language, it can be easy to miss a little detail you''d never overlook in a familiar environment. The Rust''s compiler is rather good at telling the user what they''re doing wrong, but for a beginner it can be difficult to understand more advanced errors. I got one while going through the [Diesel ORM Getting Started](https://diesel.rs/guides/getting-started) guide. Let''s explore it!','While learning a new programming language, it can be easy to miss a little detail you''d never overlook in a familiar environment. The Rust''s compiler is rather good at telling the user what they''re doing wrong, but for a beginner it can be difficult to understand more advanced errors. I got one while going through the [Diesel ORM Getting Started](https://diesel.rs/guides/getting-started) guide. Let''s explore it!

```shell
 --> src/models.rs:7:13n  |
 7 |     pub id: i32,
   |             ^^^ the trait `FromSql<diesel::sql_types::Nullable<diesel::sql_types::Integer>, Sqlite>` is not implemented for `i32`
   |
     = help: the trait `FromSql<diesel::sql_types::Integer, Sqlite>` is implemented for `i32`
     = note: required for `i32` to implement `diesel::Queryable<diesel::sql_types::Nullable<diesel::sql_types::Integer>, Sqlite>`
     = note: required for `i32` to implement `FromSqlRow<diesel::sql_types::Nullable<diesel::sql_types::Integer>, Sqlite>`
     = help: see issue #48214
```

My model:

```rust
use diesel::prelude::*;

#[derive(Queryable, Selectable)]
#[diesel(table_name = crate::schema::posts)]
#[diesel(check_for_backend(diesel::sqlite::Sqlite))]
pub struct Post {
    pub id: i32,
    pub title: String,
    pub body: String,
    pub published: bool,
}
```

My table:

```sql
CREATE TABLE posts (
    id INTEGER PRIMARY KEY AUTOINCREMENT, -- NOT NULL is missing
    title TEXT(64) NOT NULL,
    body TEXT NOT NULL,
    published BOOLEAN NOT NULL DEFAULT 0
)
```

Naturally, since the `id` field is not marked as `NOT NULL`, the value is optional. However, the struct states that the expected type for the `id` field is `i32`. Professionally I''ve been working with Java, where null values are part of the game. That''s why I didn''t even think about this discrepancy. In Rust, on the other hand, there are no null values.

Therefore, I should either make this field optional in the struct:

```rust
use diesel::prelude::*;

#[derive(Queryable, Selectable)]
#[diesel(table_name = crate::schema::posts)]
#[diesel(check_for_backend(diesel::sqlite::Sqlite))]
pub struct Post {
    pub id: Option<i32>, // allow null values
    pub title: String,
    pub body: String,
    pub published: bool,
}
```

Or modify the table:

```sql
CREATE TABLE posts (
    id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL, -- value must be specified
    title TEXT(64) NOT NULL,
    body TEXT NOT NULL,
    published BOOLEAN NOT NULL DEFAULT 0
)
```

If you change the migration script, don''t forget to recreate the schema with `diesel migration redo`. Never modify the `schema.rs` file manually.

When the issue is localized and solved, it''s easier to understand the error:

```shell
 --> src/models.rs:7:13
  |
7 |     pub id: i32,
  |             ^^^ the trait `FromSql<diesel::sql_types::Nullable<diesel::sql_types::Integer>, Sqlite>` is not implemented for `i32`
  |
    = help: the trait `FromSql<diesel::sql_types::Integer, Sqlite>` is implemented for `i32`
```

The `schema.rs` file describes the table based on the actual sql request in the `migrations/` directory. In my case, the `id` field wasn''t marked as `NOT NULL`, so the schema specified it as nullable.

```rust
diesel::table! {
    posts (id) {
        id -> Nullable<Integer>,
        title -> Text,
        body -> Text,
        published -> Bool,
    }
}
```

The compiler detected the mistmatch between the schema and the struct:

```shell
 --> src/models.rs:7:13n  |
7 |     pub id: i32,
  |             ^^^ the trait `FromSql<diesel::sql_types::Nullable<diesel::sql_types::Integer>, Sqlite>` is not implemented for `i32`
```

And even suggested that the `i32` type has the following trait implemented:

```shell
  = help: the trait `FromSql<diesel::sql_types::Integer, Sqlite>` is implemented for `i32`
```

Instead of `FromSql<diesel::sql_types::Nullable<diesel::sql_types::Integer>, Sqlite>`.

Now I know what this means. Learning new stuff is fun! I can also recommend these two courses:

- [Ultimate Rust Crash Course](https://www.udemy.com/course/ultimate-rust-crash-course/)
- [Ultimate Rust 2: Intermediate Concepts](https://www.udemy.com/course/ultimate-rust-2/)

To my taste, the crash course was a bit shallow, because core topics like the errors handling are part of the intermediate course. But together these courses helped me in gaining confidence, and I enjoyed Nathan''s style. The [official book](https://doc.rust-lang.org/book/) is deeper, of course, since it''s a book. At the same time, it can be hard to consume and store all details in your memory. However, after taking these courses I can use the book to expand my knowledge.','Understanding Rust and Diesel: Handling nullable fields in models',1),
                                                            ('6548f9ea0608211506b68780','2023-11-06T14:35:29.640Z','The modern internet is highly centralized. While independent websites still exist, we rarely go beyond the firsrt few search results and get news from social media. These platforms are _the_ internet for many people because they not only help old friends stay in touch, but also act as content aggregators and providers, enabling algorithms to control what we see.

Recent changes on now X and Reddit pushed me to take a look at decentralized solutions. I joined [Lemmy](https://join-lemmy.org/) and [Mastodon](https://joinmastodon.org/). Both are significantly smaller than their commercial counterparts and don''t have as much content, which makes mindless scrolling for hours impossible. This change alone freed up a lot of time and helped me realize how addictive these services are.

On the other hand, the absence of a ''smart feed'' puts responsibility of finding new content on the user. As I discovered, people continue to post on personal blogs, and some websites still generate RSS feeds. I believe it''s important to have full control over our feeds. The cheap pleasure that comes with scrolling social media harms our lives and distracts us from our long-term goals. Instead of doing something useful, we spend endless hours arguing with strangers and watching memes.

Algorithms'' job is to keep us engaged, they don''t care whether we get useful information or engage in benificial activities in the process. In fact, platforms like Facebook [profit off hate speech and misinformation](https://www.euronews.com/next/2021/10/04/facebook-profits-off-hate-and-that-s-why-it-won-t-change-says-whistleblower-frances-haugen). See also: [How Facebook Became a Tool for Genocide](https://www.youtube.com/watch?v=K8B0bWO9u3M).

To be part of the solution and not the problem, I decided to launch this blog a couple of months ago. Now, I want to introduce an RSS feed that should make following me easier. Let''s see how I implemented it with ROME, Spring Boot, Docker and Nginx!','The modern internet is highly centralized. While independent websites still exist, we rarely go beyond the firsrt few search results and get news from social media. These platforms are _the_ internet for many people because they not only help old friends stay in touch, but also act as content aggregators and providers, enabling algorithms to control what we see.

Recent changes on now X and Reddit pushed me to take a look at decentralized solutions. I joined [Lemmy](https://join-lemmy.org/) and [Mastodon](https://joinmastodon.org/). Both are significantly smaller than their commercial counterparts and don''t have as much content, which makes mindless scrolling for hours impossible. This change alone freed up a lot of time and helped me realize how addictive these services are.

On the other hand, the absence of a ''smart feed'' puts responsibility of finding new content on the user. As I discovered, people continue to post on personal blogs, and some websites still generate RSS feeds. I believe it''s important to have full control over our feeds. The cheap pleasure that comes with scrolling social media harms our lives and distracts us from our long-term goals. Instead of doing something useful, we spend endless hours arguing with strangers and watching memes.

Algorithms'' job is to keep us engaged, they don''t care whether we get useful information or engage in benificial activities in the process. In fact, platforms like Facebook [profit off hate speech and misinformation](https://www.euronews.com/next/2021/10/04/facebook-profits-off-hate-and-that-s-why-it-won-t-change-says-whistleblower-frances-haugen). See also: [How Facebook Became a Tool for Genocide](https://www.youtube.com/watch?v=K8B0bWO9u3M).

To be part of the solution and not the problem, I decided to launch this blog a couple of months ago. Now, I want to introduce an RSS feed that should make following me easier. Let''s see how I implemented it with ROME, Spring Boot, Docker and Nginx!

## Idea

I had the following algorithm in my head:

1. Generate an RSS feed.
1. Write the feed to a file.
1. Put the file to a directory that Nginx exposes to the web.
1. Add a link to the file in the webapp.

One might argue that the backend service could handle steps 2 and 3 since it already has numerous controllers. Indeed, this is a viable option. However, generating the feed for each request is a resource-consuming operation, although it isn''t really heavy or abnormal for a Spring Boot app. I could also add caching. After all, a bunch of RSS readers pulling the feed 24/7 might create some load. But let''s be honest, my blog is not operating at that scale.

The simple fact that there''s absolutely no need to generate the feed dynamically convinced me to go with the initial plan.

## Generate feed

To generate the feed, I chose the [ROME](https://rometools.github.io/rome/index.html) library. According to [Maven](https://mvnrepository.com/tags/rss), it''s the most popular library for this job, the development is still in progress, plus it comes with good documentation. I used [this article](https://rometools.github.io/rome/RssAndAtOMUtilitiEsROMEV0.5AndAboveTutorialsAndArticles/RssAndAtOMUtilitiEsROMEV0.5TutorialUsingROMEToCreateAndWriteASyndicationFeed.html) as a reference.

First, get posts by calling the `PostService`:

```java
List<SyndEntry> entries = postService.getPosts(1, rssFeedItems)
    .getItems()
    .stream()
    .map(this::mapPostToEntry)
    .toList();
```

The service already had had the `getPosts(page, pageSize)` method implemented for the respective API controller. Here, I had to add a mapper to convert my posts to feed entires.

```java
private SyndEntry mapPostToEntry(PostPreviewDto post) {
    SyndContentImpl description = new SyndContentImpl();
    description.setValue(post.getSummary());

    SyndEntry entry = new SyndEntryImpl();
    entry.setUri(post.getId());
    entry.setTitle(post.getTitle());
    entry.setDescription(description);
    entry.setLink(format(rssFeedLinkFormat, post.getId()));

    return entry;
}
```

Another option would be to implement the `SyndEntry` interface for my `PostPreviewDto` to avoid this conversion. I didn''t do this because the interface defines 40 methods, it''d be confusing to have all these extra methods in the `PostPreviewDto` class. Imagine how code suggestions would look like!

It''d also be redundant, as I''m using only four fields:

1. Uri or guid - a unique identifier of the post, i.e. permanent url or id from the database.
1. Title - a title of the post.
1. Description - a short description of the post. I decided to put the post''s summary there, that''s the text that you see on the front page.
1. Link - a link to the full post.

This is how one of the posts looks in Miniflux:

![My blog''s post in Miniflux](/media/6548f9ea0608211506b68780/miniflux-post.png)

Yes, I''ve intentionally picked up a post without markdown in its description for the screenshot. RSS readers don''t convert markdown to HTML. I have to address this issue in the future.

Now that entries have been retrieved and mapped, the feed object can be created:

```java
SyndFeedImpl feed = new SyndFeedImpl();
feed.setFeedType(rssFeedType);
feed.setTitle(rssFeedTitle);
feed.setDescription(rssFeedDescription);
feed.setLink(rssFeedWebsiteLink);
feed.setEntries(entries);
```

ROME supports various kinds of RSS and Atom, it''s up to the user to decide which to use. I chose `rss_2.0`. Discrepancies between different versions don''t matter to me, at least at this point, so let it be the latest edition of the RSS specification. Other fields, I suppose, are self-explanatory.

The feed can finally be saved to a file:

```java
try (FileWriter writer = new FileWriter(rssFeedOutputFile)) {
    new SyndFeedOutput().output(feed, writer);
}
```

## Schedule task

Spring Boot comes with a built-in scheduler. A couple of annotations enable it and mark the method that should be executed under the specified condition.

```java
@Configuration
@EnableScheduling
public class JobScheduler {
    @Scheduled(cron = "${rss.feed.cronExpression}")
    public void generateRssFeed() {
        // code that handles the feed generation
        // we''ve discussed it above
    }
}
```

I went with a cron expression because it''s a familiar tool that allows fine-tuning. Here are the values that I used locally for testing:

```properties
# every hour
rss.feed.cronExpression=0 0 * * * *

# every minute
rss.feed.cronExpression=0 * * * * *

# every second
rss.feed.cronExpression=* * * * * *
```

You can see in [my repository](https://codeberg.org/parfentjev/simple-blog/src/branch/main/backend/src/main/java/ee/fakeplastictrees/blog/core/configuration/JobScheduler.java) how the feed generator and job scheduler work together.

## Serve output

The code above generates a file on the disk, which is not available for the end user yet. Thanks to my poor knowledge of Docker and Docker Compose, this part of the task turned out to be the hardest! Well, now I know a little bit more, and that''s one of the goals behind this blog.

As I said at the beginning, Nginx is tasked to serve the feed. The following configuration exposes `/path/to/directory/with/static/files`, where `feed.xml` is stored, to the outer world:

```
location /static {
    alias /path/to/directory/with/static/files;
}
```

Only the file is not in this directory yet. The backend service is running in a Docker container with its own filesystem, and we have to map it to a file on the host system that Nginx is working with.

To achieve that, the container had to be reconfigured:

```
services:
  backend:
    # Long story short...
    volumes:
        - /path/to/directory/with/static/files/feed.xml:/backend/feed.xml
```

The single `volumes` entry says:

- Okay, there''s a `/path/to/directory/with/static/files/feed.xml` file on the host system.
- I want to map it to a `/backend/feed.xml` file in the container.
- This way, when `/backend/feed.xml` changes, the updated `feed.xml` will be served to users pulling it via `http://website.com/static/feed.xml`.

Here''s one caveat I wasn''t aware of: `/path/to/directory/with/static/files/feed.xml` should exist _before_ building the image. Otherwise, Docker will create a directory called `feed.xml`, which is not what we need here.

## Conclusion

The Java ecosystem is fantastic, it provides powerful and established libraries. There''s plenty of documentation and examples online, you can always find some help. I especially appreciate this after working with Rust, Actix and Diesel. Don''t get me wrong, these are great tools. It''s just that the community is not that big yet.

The feature is completed and deployed: now, if one wishes to follow my blog, he or she can add my RSS feed to their reader. It''s also possible to map it to some other medium, as there are various `RSS <--> Something Else` bridges. I also had to update the webapp, and with that, I made little improvements, mostly aimed at users browsing with their mobile phones. Great success!
','How to generate RSS feed with ROME and Spring Boot',1),
                                                            ('6550eb40390cba57c7bdd7df','2023-11-12T15:10:14.500Z','It can be hard to decide how to spend our free time. We may have some ideas about activities to engage in, but our brains prefer not to invest effort in something deemed unrewarding. Alas, among such things we can find work on quite useful tasks. Usually these activities don''t yield immediate tangible output, and it takes months and years to achieve our goals. Say, learning a new language or obtaining any other comprehensive skill. Consequently, our motivation tends to fade off over time. Faced with a choice between difficult or boring tasks and something easy, we often succumb to the temptation, and turn to social media or TV shows.

This summary is based on two books I''ve recently read: ["Thinking, Fast and Slow"](https://us.macmillan.com/books/9780374533557/thinking-fast-and-slow) by Daniel Kahneman and ["Willpower and self-control: How genes and the brain hinder our struggle against temptations"](https://nonfiction.ru/books/volya-i-samokontrol-kak-genyi-i-mozg-meshayut-nam-borotsya-s-soblaznami) by Irina Yakutenko. The former explores how our brains trick us from a psychologist''s perspective, the latter is focused on biochemical processes.

To mitigate this problem, I started creating to-do lists. Having a clear path to follow makes it much easier to stay on the course. No doubt, there are various causes of procrastination, and what works for one individual may not work for another. But to-do lists can be a valuable ally for many people.

I''d like to share my experience on how I''ve managed to organize my time better.','It can be hard to decide how to spend our free time. We may have some ideas about activities to engage in, but our brains prefer not to invest effort in something deemed unrewarding. Alas, among such things we can find work on quite useful tasks. Usually these activities don''t yield immediate tangible output, and it takes months and years to achieve our goals. Say, learning a new language or obtaining any other comprehensive skill. Consequently, our motivation tends to fade off over time. Faced with a choice between difficult or boring tasks and something easy, we often succumb to the temptation, and turn to social media or TV shows.

This summary is based on two books I''ve recently read: ["Thinking, Fast and Slow"](https://us.macmillan.com/books/9780374533557/thinking-fast-and-slow) by Daniel Kahneman and ["Willpower and self-control: How genes and the brain hinder our struggle against temptations"](https://nonfiction.ru/books/volya-i-samokontrol-kak-genyi-i-mozg-meshayut-nam-borotsya-s-soblaznami) by Irina Yakutenko. The former explores how our brains trick us from a psychologist''s perspective, the latter is focused on biochemical processes.

To mitigate this problem, I started creating to-do lists. Having a clear path to follow makes it much easier to stay on the course. No doubt, there are various causes of procrastination, and what works for one individual may not work for another. But to-do lists can be a valuable ally for many people.

I''d like to share my experience on how I''ve managed to organize my time better.

## General idea

I started with simple notes in Nextcloud, placing a literal list of tasks for each day. The same can be done in any text editor, be it GNU nano or Notepad. For example:

- Clean the kitchen
- Meditate
- Study math: complete one unit and pass exercises
- Udemy: watch videos about a single concept, complete relevant exercises
- Develop a feature: generate an RSS feed for my blog

It''s important not to make the list too long. It should be possible to finish all tasks in one day. Otherwise, constant frustration caused by discontent with our inability to clean the list and follow the plan might push us away from making plans altogether. Moreover, if we put too many items on the list, we might start picking up easier and more joyous activities instead of important ones.

Goals should be clear. Look at these three lines:

- Study math: complete one unit and pass exercises
- Udemy: watch videos about a single concept, complete relevant exercises
- Develop a feature: generate an RSS feed for my blog

And compare them to these:

- Study math
- Watch videos on Udemy
- Work on my blog

For how long should I study math? How many videos on Udemy are enough? What kind of work do I need to do with my blog, what am I trying to achieve? I can''t achieve targets if there are no targets! My tired brain can always say: "Okay, that''s enough, let''s watch YouTube instead."

Perhaps a reader, who is working in IT, is familiar with these ideas. In software development, we also plan tasks, usually for a week or two ahead, and break big things into smaller units of work. This realization induced me to configure a [Kanban](https://en.wikipedia.org/wiki/Kanban) board and use it as a to-do list.

## Kanboard

I deployed [Kanboard](https://kanboard.org/), a great open-source tool. Its web-interface is simple and fast, it can work with an SQLite database, making it lightweight.

![Kanboard](/media/6550eb40390cba57c7bdd7df/kanboard.png)

This may sound like hammering nails with a screwdriver, but in fact, software solutions specialized in to-do lists _come_ with the support of Kanban boards! Take a look at [Vikunja](https://vikunja.io/):

![Vikunja: Kanban board](/media/6550eb40390cba57c7bdd7df/vikunja-kanban-board.png)

In essence, Kanban is a system that helps organize work. We have a backlog of tasks, we prioritize and plan them, we take them in progress, and complete them. All of this is as true for to-do lists as for a factory or an IT-company.

Kanban''s key feature, the [Work In Progress (WIP) limit](https://www.atlassian.com/agile/kanban/wip-limits), is helpful in personal life too. Without any limits, the "in progress" column can grow over time and turn into another backlog.

1. We start working on Item #1.
1. We get stuck or distracted.
1. We decide to take Item #2.
1. We don''t finish it again for any reason.
1. We repeat steps above over and over.

However, if we limit ourselves to N items in progress, we''re incentivized to finish existing tasks to be able to take new ones. I think this is a fantastic feature of Kanban and is the reason why I prefer it over Scrum.

Kanban is not strict. There''s no rule saying that N should be equal to 1, 3, or any other number. For myself, I find WIP=2 to be the optimal value. There''s always room for an item I''m currently focused on, but that also leaves a spot if something urgent pops up.

The usage of specialized software makes it easier to address concerns discussed in the Notes section. Items that would be nice to do and items that have to be done first are separated thanks to the "backlog" and "to do" columns. Tasks in the backlog can be prioritized to plan the most valuable activities first.

Links between tasks help visualize the hierarchy of work items. If I need to accomplish Z, but I see that it''s blocked by Y, which is itself blocked by X, then it''s obvious where to start - with X. Moreover, if Z has a definitive deadline, I can plan X and Y accordingly.

We can even analyze lead time and other data to maximize our efficiency! Not that I manage my life _that_ meticulously.

## Conclusion

Kanban is a fantastic framework for to-do lists. Software like Kanboard comes with a set of tools to effectively organize items and provide enough flexibility to adjust to your needs. By no means I do argue that it is _the best_ choice. You may find something more suitable for your requirements. Yet, I''m fully satisfied with it.

I suggest giving to-do lists a try. You can start with a simple text-based list like I did. With the right approach, it can be very helpful.','My approach to to-do lists powered by Kanboard',1),
                                                            ('6554de83390cba57c7bdd7e0','2023-11-15T15:04:02.890Z','A couple of days ago, I took on an interesting task on [Exercism](https://exercism.org/). You can find the full description [here](https://exercism.org/tracks/java/exercises/secret-handshake). The goal is to create a function that takes a number between 1 and 31 and converts it to a list of actions. The sequence is defined by the five rightmost digits of the number when converted to binary. If you''re unfamiliar with the binary system, I recommend reading [this explanation](https://www.bbc.co.uk/bitesize/topics/zgv8dp3/articles/z9j2jsg) first.

In this post, I''ll discuss how I gradually improved my initial solution and share some interesting findings about the performance of different approaches.','A couple of days ago, I took on an interesting task on [Exercism](https://exercism.org/). You can find the full description [here](https://exercism.org/tracks/java/exercises/secret-handshake). The goal is to create a function that takes a number between 1 and 31 and converts it to a list of actions. The sequence is defined by the five rightmost digits of the number when converted to binary. If you''re unfamiliar with the binary system, I recommend reading [this explanation](https://www.bbc.co.uk/bitesize/topics/zgv8dp3/articles/z9j2jsg) first.

In this post, I''ll discuss how I gradually improved my initial solution and share some interesting findings about the performance of different approaches.

## Given

Here are possible actions in binary form:

```
00001 = wink
00010 = double blink
00100 = close your eyes
01000 = jump
10000 = reverse the order of the operations
```

Let''s consider the input number as 5. Then, the expected action list is "wink, close your eyes", since 5 is `00101` in binary form.

```
0010|1| = 5
0000|1| = wink - the input number has 1 in the same column, so we add the action

001|0|1 = 5
000|1|0 = double blink - the input number has 0 in the same column, so skip the action

00|1|01 = 5
00|1|00 = close your eyes - the input number has 1 in the same column, so add the action

0|0|101 = 5
0|1|000 = jump - the input number has 0 in the same column, so skip the action

|0|0101 = 5
|1|0000 = reverse the order of the operations - the input number has 0 in the same column, so skip the action
```

I assume that not all software developers regularly work with binary numbers in high-level languages like Java, let alone test engineers like me. Naturally, I wasn''t even aware of the tools I could use.

## My approach

Before discussing alternative solutions, let''s examine my first attempt and enhance it a little. I _do_ dare to say that it''s not perfect.

```java
List<Signal> calculateHandshake(int number) {
    List<Signal> signals = new ArrayList<>();
    String binaryString = "0000" + Integer.toBinaryString(number);

    int wink = binaryString.length() - 1;
    int doubleBlink = binaryString.length() - 2;
    int closeYourEyes = binaryString.length() - 3;
    int jump = binaryString.length() - 4;
    int reverse = binaryString.length() - 5;

    for (int i = binaryString.length() - 1; i >= 0 && i >= reverse; i--) {
        if (binaryString.charAt(i) != ''1'') {
            continue;
        }

        if (i == wink) {
            signals.add(Signal.WINK);
        } else if (i == doubleBlink) {
            signals.add(Signal.DOUBLE_BLINK);
        } else if (i == closeYourEyes) {
            signals.add(Signal.CLOSE_YOUR_EYES);
        } else if (i == jump) {
            signals.add(Signal.JUMP);
        } else if (i == reverse) {
            Collections.reverse(signals);
        }
    }

    return signals;
}
```

You, probably:

![Parks and Recreation: Throwing away a computer](/media/gifs/throwing-away-computer.gif)

I didn''t know how to solve this. Eventually, I got stuck and mixed different ideas together. I intended to iterate over the binary string from `binaryString.length()` to minus 5, with five possible actions in mind. Alas, a binary value might be less than 5 characters, such as 9 (`1001`).

I then considered taking four zeroes and appending the binary string to them. Thi way, I would always have at least 5 positions to iterate over them.

```java
String binaryString = "0000" + Integer.toBinaryString(number);
```

Yet, the string''s length wasn''t fixed to 5. With `"0000" + "1001" = "00001001"` the length would be 8. Thus, the exact position bound to each action had to be calculated dynamically based in the length.

```java
// binaryString = 00001001
int wink = binaryString.length() - 1; // last char: ...0100|1|
int doubleBlink = binaryString.length() - 2; // next char: ...010|0|1
int closeYourEyes = binaryString.length() - 3; // etc.
int jump = binaryString.length() - 4;
int reverse = binaryString.length() - 5;
```

An alternative method to add missing characters is to use `String.format`:

```java
// The %s value will be extended to 5 characters if needed
String.format("%5s", Integer.toBinaryString(number))

// "1001" -> " 1001" - a whitespace is added at the beginning
```

Although "\_1001"is not the same as "01001". However, it doesn''t matter in the context of this exercise. We only want to know if a character at a given position is equal to 1. It doesn''t matter whether it''s a zero, a whitespace or anything else, as long as it isn''t 1.

Here''s a caveat: if the input number is greater than 31 (`11111`), the binary representation will exceed 5 characters. Unfortunately, despite the specified requirements, one of the Exorcism''s tests is using the input vlaue of 35 (`100011`). In other words, the binary string is not guaranteed to be <= 5 characters.

```java
String binaryString = String.format("%5s", Integer.toBinaryString(number));

// "100011" -> "100011", not "00011" ð
```

I addressed this issue with a regular expression that extracts the last five digits:

```java
String binaryString = String.format("%5s", Integer.toBinaryString(number)).replaceAll(".+(.{5})", "$1");

// "100011" -> "00011" ð»
```

This approach should also work with the concatenation. With static indexes, checking characters at each position is trivial.

```java
// Let''s say, that the number = 5
List<Signal> calculateHandshake(int number) {
    List<Signal> signals = new ArrayList<>();
    String binaryString = String.format("%5s", Integer.toBinaryString(number)).replaceAll(".+(.{5})", "$1");

    // 0010|1| = true, we have 1 in this position
    if (binaryString.charAt(4) == ''1'') {
        signals.add(Signal.WINK);
    }

    // 001|0|1 = false, we have 0 in this position
    if (binaryString.charAt(3) == ''1'') {
        signals.add(Signal.DOUBLE_BLINK);
    }

    // 00|1|01 = true, we have 1 in this position
    if (binaryString.charAt(2) == ''1'') {
        signals.add(Signal.CLOSE_YOUR_EYES);
    }

    // 0|0|101 = false, we have 0 in this position
    if (binaryString.charAt(1) == ''1'') {
        signals.add(Signal.JUMP);
    }

    // |0|0101 = false, we have 0 in this position
    if (binaryString.charAt(0) == ''1'') {
        Collections.reverse(signals);
    }

    // [WINK, CLOSE_YOUR_EYES]
    return signals;
}
```

## Bitwise operators

On Exercism, you can see how others solved the same task in the [community solutions](https://exercism.org/tracks/java/exercises/secret-handshake/solutions) section. That''s where I found out about [bitwise operators](https://www.baeldung.com/java-bitwise-operators). This feature is not confined to Java, you can use it in [Python](https://www.w3schools.com/python/gloss_python_bitwise_operators.asp), [Rust](https://doc.rust-lang.org/book/appendix-02-operators.html), [JavaScript](https://www.w3schools.com/js/js_bitwise.asp), [C#](https://learn.microsoft.com/en-us/dotnet/csharp/language-reference/operators/bitwise-and-shift-operators), and probably many other languages.

Behind the scenes, bitwise operators work with binary values, but we can apply them to integers and chars too. For this exercise, the **AND (&)** operator is often used. Unlike the regular **AND (&&)**, its bitwise counterpart is expressed with a single ampersand, not two.

1. Let''s consider two values: `v1=5` and `v2=4`.
1. In the code, we can apply one of the bitwise operators to them: `v1 & v2`.
1. Each bit will be compared to determine if both are equal to 1.
1. It''s similar to the regular AND (&&) operator applied to booleans:
   - `true && true = true`
   - `true && false = false`
   - `false && false = false`

Same values in form of a table:

```
| 16  | 8   | 4   | 2   | 1   | Description         |
| --- | --- | --- | --- | --- | ------------------- |
| 0   | 0   | 1   | 0   | 1   | v1=5                |
| 0   | 0   | 1   | 0   | 0   | v2=4                |
| 0   | 0   | 1   | 0   | 0   | output of `v1 & v2` |
```

Since `5 & 4` returns `4`, we know for a fact that there''s 1 in the third position, meaning that the action must added to the list.

```
| binary | decimal | action                              |
| ------ | ------- | ----------------------------------- |
| 00001  | 1       | wink                                |
| 00001  | 2       | double blink                        |
| 00100  | 4       | close your eyes                     |
| 01000  | 8       | jump                                |
| 10000  | 16      | reverse the order of the operations |
```

All this leads to the following solution, where we compare the input value to decimal numbers, associated with possible actions:

```java
// Let''s say, that the number = 5
List<Signal> calculateHandshake(int number) {
    List<Signal> signals = new ArrayList<>();

    // 5 = 0010|1|
    // 1 = 0000|1|
    //
    // The result of this comparison is 00001 or 1
    // The condition is true
    if ((number & 1) == 1) {
        signals.add(Signal.WINK);
    }

    // 5 = 001|0|1
    // 2 = 000|1|0
    //
    // The result of this comparison is 00000 or 0
    // The condition is false
    if ((number & 2) == 2) {
        signals.add(Signal.DOUBLE_BLINK);
    }

    // 5 = 00|1|01
    // 4 = 00|1|00
    //
    // The result of this comparison is 00100 or 4
    // The condition is true
    if ((number & 4) == 4) {
        signals.add(Signal.CLOSE_YOUR_EYES);
    }

    // 5 = 0|0|101
    // 8 = 0|1|000
    //
    // The result of this comparison is 00000 or 0
    // The condition is false
    if ((number & 8) == 8) {
        signals.add(Signal.JUMP);
    }

    // 05 = |0|0101
    // 16 = |1|0000
    //
    // The result of this comparison is 00000 or 0
    // The condition is false
    if ((number & 16) == 16) {
        Collections.reverse(signals);
    }

    // [WINK, CLOSE_YOUR_EYES]
    return signals;
}
```

Another way to solve this task would be to use the bitwise left shift operator (`<<`). It''s based on the same idea, so I suggest figuring this out yourself.

```java
List<Signal> calculateHandshake(int number) {
    List<Signal> signals = new ArrayList<>();

    if ((number & 1) == 1) {
        signals.add(Signal.WINK);
    }

    if ((number & 1 << 1) != 0) {
        signals.add(Signal.DOUBLE_BLINK);
    }

    if ((number & 1 << 2) != 0) {
        signals.add(Signal.CLOSE_YOUR_EYES);
    }

    if ((number & 1 << 3) != 0) {
        signals.add(Signal.JUMP);
    }

    if ((number & 1 << 4) != 0) {
        Collections.reverse(signals);
    }

    return signals;
}
```

Check out other possible solutions on [Exercism](https://exercism.org/tracks/java/exercises/secret-handshake/solutions).

## Performance

[Choosing between ArrayList and LinkedList](https://www.youtube.com/watch?v=ul4wHrbJ8Fk) is a great video that introduced me to the [JMH](https://github.com/openjdk/jmh) benchmark. Arguing over which approach is better can be fun, but that''s often based on our limited experience and subjective opinions. Let''s collect some objective data instead!

I tested all three implementations described above with four values:n

1. 1 - the minimal number according to the exercise.
1. 31 - the maximal number according to the exercise.
1. 1024 - an allegedly more realistic number that could serve as the input value.
1. 998 - not a base 2 number as the opposition to 1024, we''ll discuss this below.

I also included two solutions [suggested on the Exercism website](https://exercism.org/tracks/java/exercises/secret-handshake/dig_deeper). Both are described in great detail [here](https://exercism.org/tracks/java/exercises/secret-handshake/approaches/for-loop) and [here](https://exercism.org/tracks/java/exercises/secret-handshake/approaches/intstream).

### Results

```
| Method | MIN ops/s   | MAX ops/s   | REALISTIC ops/s | NOT_BASE_2 ops/s |
| ------ | ----------- | ----------- | --------------- | ---------------- |
| String | 2,887,108   | 2,910,968   | 2,040,287       | 2,068,403        |
| Bit &  | 310,184,337 | 125,008,401 | 2,320,036,065   | 302,718,931      |
| Bit << | 310,529,569 | 124,772,256 | 2,318,228,556   | 300,684,083      |
| Loop   | 181,952,427 | 78,555,464  | 3,818,534,904   | 125,523,998      |
| Stream | 21,260,678  | 14,653,600  | 27,503,337      | 19,653,348       |
```

![Chart: Performance testing results](/media/6554de83390cba57c7bdd7e0/performance-results-chart.png)

All results are rounded to the nearest one.

See also:

- [Test implementation](https://codeberg.org/parfentjev/jmh-benchmark/src/branch/main/secret-handshake/src/main/java/ee/fakeplastictrees/SecretHandshakeBenchmark.java)
- Raw results:
  - [Part 1](https://codeberg.org/parfentjev/jmh-benchmark/src/branch/main/secret-handshake/results-v1.txt)
  - [Part 2](https://codeberg.org/parfentjev/jmh-benchmark/src/branch/main/secret-handshake/results-v2.txt)

### Observations

Unsurprisingly, the approach that involved string formatting and a regular expression is the slowest one. The graph illustrates this well. The bars representing the string method are barely visible.

The most surprising result is the performance of the [IntStream](https://exercism.org/tracks/java/exercises/secret-handshake/approaches/intstream) method. It''s still 5 to 14 times better than the string method, yet it''s also 8 to 84 times slower than the bitwise methods.

Another noteworthy result is the amount of operations for the "realistic" number (1024). My assumption is that this is because 1024 can be represented by a single 1 (`10000000000`). I''m not sure why tests that used the MIN value (`1`) didn''t produce similar numbers. Nevertheless, I re-executed tests with 998 (`1111100110`) as the input value to test my theory. This number is close to 1024, but its binary form isn''t as simple. As expected, the score for this value was not abnormally high.

Perhaps, this could be caused by how data is stored in memory and shared with the CPU''s cache. Besides, as a test engineer, I''m well aware that tests can produce incorrect results due to mistakes in tests themselves or other factors influencing test execution. That''s why I shared my code above for you to double-check.

With that in mind, both bitwise implementations seem to have the best performance. [For loop](https://exercism.org/tracks/java/exercises/secret-handshake/approaches/for-loop) is 2 to 8 times slower with the IntStream and string methods trailing far behind. The only exception is the "realistic" number. If I were to implement this in some project, I''d ask myself what data my program can expect and test my hypothesis about base two numbers extensively. Who knows, maybe in a particular use-case the for loop method would be better suited?

## Conclusion

A small exercise, marked as easy on Exercism, turned out to be very insightful. I learned a bit more about string formatting in Java, discovered bitwise operators, and tried running benchmark tests. Once visualized, this data showed tremendous gaps between different approaches. I guess that''s why computer scientists are obsessed with algorithm efficiency!
','Secret Handshake: Solving an exercise using bitwise operators and comparing performance',1);
INSERT INTO posts (id,date,summary,"text",title,visible) VALUES
    ('655908253973a0380a1b9f8f','2023-11-18T18:47:39.603Z','While discussions on the topic of AI have been ongoing for years, they weren''t as prominent outside the circle of enthusiasts. That changed one year ago when [OpenAI introduced ChatGPT](https://openai.com/blog/chatgpt) in November 2022. I want to recommend a book that is relevant to the subject.','While discussions on the topic of AI have been ongoing for years, they weren''t as prominent outside the circle of enthusiasts. That changed one year ago when [OpenAI introduced ChatGPT](https://openai.com/blog/chatgpt) in November 2022. A chart below shows rapid growth of interest in this subject.

From [Google Trends](https://trends.google.com/trends/explore?date=2022-09-01%202023-11-17&q=ai&hl=en-US):

> Numbers represent search interest relative to the highest point on the chart for the given region and time. A value of 100 is the peak popularity for the term. A value of 50 means that the term is half as popular. A score of 0 means there was not enough data for this term.

![Google Trends: Interest over time for AI and space](/media/655908253973a0380a1b9f8f/interest-over-time-ai.png)

Over this period, we''ve seen countless attempts to apply ChatGPT and other generative tools like Modjourney with various degrees of success. I use ChatGPT regularly because it''s a great tool that can be very helpful. At the same time, some people [were replaced by AI](https://www.businessinsider.com/ai-chatgpt-jobs-replaced-by-tech-translator-2023-9), websites use it to automatically [grab content from Reddit](https://arstechnica.com/gaming/2023/07/redditors-prank-ai-powered-news-mill-with-glorbo-in-world-of-warcraft/), certain actors simply employ AI to [produce fake content and reviews](https://www.theverge.com/2023/5/2/23707788/ai-spam-content-farm-misinformation-reports-newsguard), and many human-powered writers composed a tremendous amount of posts on the topic. Count this one too!

From what I see, there are two dominant lines of thought. Proponents of the first approach are optimistic, they believe that AI will solve all our problems and lead us to a better place. Their opponents are afraid that AI will only deepen the already growing level of economic inequality, rendering regular people less powerful in a political sense. Considering these divergent views, the question inevitably arises: which camp is right?

We don''t know yet, as nothing is predetermined. It''s the direction of development and the application of AI-driven solutions that will decide the outcome. In short, this is what [Power and Progress: Our Thousand-Year Struggle Over Technology and Prosperity](https://www.goodreads.com/book/show/62315566-power-and-progress) by Daron AcemoÄlu and Simon Johnson is about. They argue that innovations benefit elites not because this is an intrinsic feature of technologies, but because elites have the means to steer their development.

To support this thesis, the book includes examples from history, covering the period from the first agricultural revolution to post-World War II growth, and pointing to differences in how technologies were applied and policied. With the right approach, the authors insist, innovations can lead to shared prosperity. However, that''s not going to happen on its own.

With that, "Power and Progress" can serve as a valuable guide as we navigate through the uncertain terrain of AI advancements. The book is written in simple English language. You don''t need any prior knowledge of politics, economics, or technologies to understand it. I recommend reading it.','"Power and Progress": Important book about technologies at our doorstep',1);
